{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68da5830-3be4-42cf-8052-dd2d4b2126e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from Bio import Seq, SeqIO, Align, pairwise2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20ada89-b709-483f-980e-94735f754a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_pair_reads(directory, fastq1_name, fastq2_name):\n",
    "    \"\"\"\n",
    "    Importing the fastq sequences and their reverse complement\n",
    "    \"\"\"\n",
    "    \n",
    "    reads1, reads2 = [], []\n",
    "    q1, q2 = [], []\n",
    "    \n",
    "    fastq1 = SeqIO.parse(directory+fastq1_name, \"fastq\")\n",
    "    for record in fastq1:\n",
    "        reads1.append(record.seq)\n",
    "        q1.append(record.letter_annotations[\"phred_quality\"])\n",
    "\n",
    "    fastq2 = SeqIO.parse(directory+fastq2_name, \"fastq\")\n",
    "    for record in fastq2:\n",
    "        reads2.append(record.seq)\n",
    "        q2.append(record.letter_annotations[\"phred_quality\"])\n",
    "    \n",
    "    return reads1, reads2, q1, q2\n",
    "\n",
    "\n",
    "def join_by_q(r1, r2, q1, q2):\n",
    "    \"\"\"\n",
    "    Given two sequences and the qualities at each position it returns the sequence\n",
    "    having the letter with larger quality and the best qualities\n",
    "    \"\"\"\n",
    "    q1, q2 = np.array(q1), np.array(q2)\n",
    "    res =  np.where(q1>q2, list(r1), list(r2))\n",
    "    qs = np.where(q1>q2, q1, q2)\n",
    "    return ''.join(res), qs\n",
    "\n",
    "\n",
    "def find_first_nucl(seq):\n",
    "    iA, iC, iT, iG = seq.find('A'), seq.find('C'), seq.find('T'), seq.find('G')\n",
    "    return min(iA, iC, iT, iG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49adc6f1-34a1-4499-94ff-41ffbe111963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_pairs(align, q1, q2):\n",
    "    \n",
    "    start_i = find_first_nucl(align.seqB)\n",
    "    # Case in which there is no gap in the reversed complement at the beginning\n",
    "    # This means that \n",
    "    if start_i==0:\n",
    "        return [], []\n",
    "    \n",
    "    # Add the first non-overlapping seqA\n",
    "    start_i_qa, start_i_qb = start_i, 0\n",
    "    seq, qs = align.seqA[:start_i], np.array(q1[:start_i])\n",
    "    \n",
    "    # Iterating over the indexes in the overlapping part\n",
    "    # start_i - last_i is the largest window of indexes without gaps\n",
    "    while start_i < len(align.seqA)-1:\n",
    "\n",
    "        # computing the positions of the overlap chunk without gaps\n",
    "        gap_indA, gap_indB = align.seqA[start_i:].find('-'), align.seqB[start_i:].find('-')\n",
    "        if gap_indA == -1: gap_indA = len(align.seqA)\n",
    "        else: gap_indA += start_i\n",
    "        if gap_indB == -1: gap_indB = len(align.seqB)\n",
    "        else: gap_indB += start_i\n",
    "        last_i = min(gap_indA, gap_indB)\n",
    "        delta = last_i-start_i\n",
    "        \n",
    "        # Joining the overlap chunk before the first gap\n",
    "        sA, sB = align.seqA[start_i:last_i], align.seqB[start_i:last_i]\n",
    "        qA, qB = q1[start_i_qa:start_i_qa+delta], q2[start_i_qb:start_i_qb+delta]\n",
    "        new_s, new_qs = join_by_q(sA, sB, qA, qB)\n",
    "        seq += new_s\n",
    "        qs = np.append(qs, new_qs)\n",
    "        start_i = last_i+1\n",
    "\n",
    "        # Resolving the gap found\n",
    "        if gap_indA < gap_indB:\n",
    "            seq += align.seqB[start_i-1]\n",
    "            start_i_qa += delta\n",
    "            start_i_qb += delta+1\n",
    "            qs = np.append(qs, q2[start_i_qb-1])\n",
    "        elif gap_indA > gap_indB:\n",
    "            seq += align.seqA[start_i-1]\n",
    "            start_i_qa += delta+1\n",
    "            start_i_qb += delta\n",
    "            qs = np.append(qs, q1[start_i_qa-1])\n",
    "        elif gap_indA == len(align.seqA):\n",
    "            break\n",
    "        else:\n",
    "            seq += align.seqA[start_i-1]\n",
    "            print('Double gap found')\n",
    "\n",
    "        # Final gap of the sequence B\n",
    "        if set(align.seqA[start_i:]) == {'-'}:\n",
    "            seq += align.seqB[start_i:]\n",
    "            qs = np.append(qs, q2[start_i_qb:])\n",
    "            #print(start_i, len(align.seqB))\n",
    "            break\n",
    "            \n",
    "    return seq, qs\n",
    "\n",
    "\n",
    "def filter_seqs(seqs, av_qs):\n",
    "    # Discarding for quality overlap and length window\n",
    "    to_keep_q, to_keep_l = set(), set()\n",
    "    for i in range(len(av_qs)):\n",
    "        if av_qs[i] > q_threshold:\n",
    "            to_keep_q.add(i)\n",
    "        #if align_scores[i] > s_threshold:\n",
    "        #    to_keep_s.add(i)\n",
    "        if len(seqs[i]) > len_bounds[0] and len(seqs[i]) < len_bounds[1]:\n",
    "            to_keep_l.add(i)\n",
    "    filt_seqs = np.take(seqs, list(to_keep_q.intersection(to_keep_l)))\n",
    "\n",
    "    # Discarding singletons\n",
    "    uniq_seqs, index, counts = np.unique(filt_seqs, return_counts=True, return_inverse=True)\n",
    "    to_keep_sing = set()\n",
    "    for i in range(len(index)):\n",
    "        if counts[index[i]] > 1:\n",
    "            to_keep_sing.add(i)\n",
    "    final_seqs = np.take(filt_seqs, list(to_keep_sing))\n",
    "    \n",
    "    return final_seqs, len(seqs)-len(to_keep_l), len(seqs)-len(to_keep_q), len(filt_seqs)-len(to_keep_sing)\n",
    "\n",
    "\n",
    "def build_seq(reads1, reads2, quals1, quals2, gap_penalty=-20):\n",
    "    \"\"\"\n",
    "    It assemble the reads1 with their reverse complement reads2 and the sequencing \n",
    "    quality at each poistion.\n",
    "    \"\"\"\n",
    "    seqs = []\n",
    "    av_qs = []\n",
    "    align_errors = []\n",
    "    #index_map = []\n",
    "\n",
    "    for i in range(len(reads1)):\n",
    "        read1, read2 = reads1[i], Seq.reverse_complement(reads2[i])\n",
    "        qual1, qual2 = quals1[i], quals2[i][::-1]\n",
    "        if set(read1) != {'A','C','G','T'} or set(read2) != {'A','C','G','T'}:\n",
    "            align_errors.append(i)\n",
    "            continue\n",
    "            \n",
    "        alignment = pairwise2.align.localms(read1, read2, 1, -1, gap_penalty, gap_penalty)[0]\n",
    "        new_seq, new_qs = join_pairs(alignment, qual1, qual2)\n",
    "        if new_seq == []:\n",
    "            align_errors.append(i)\n",
    "        else:\n",
    "            seqs.append(new_seq)\n",
    "            av_qs.append(new_qs.mean())\n",
    "            #index_map.append(i)\n",
    "            #align_scores.append(alignment.score/(alignment.end-alignment.start))\n",
    "            \n",
    "    return (*filter_seqs(seqs, av_qs), len(align_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f18756-9ea6-4845-b615-8d98977fa811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_seqs(uniq_seqs, counts, name, directory):\n",
    "    f = open(directory+name+'.fasta', 'w')\n",
    "    for i in range(len(counts)):\n",
    "        f.write('>'+str(i+1)+'_'+str(counts[i])+'\\n')\n",
    "        f.write(uniq_seqs[i]+'\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141bf8ef-527d-4c4d-916e-0b4ccb93a7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_penalty = -20\n",
    "q_threshold = 30\n",
    "len_bounds = [400, 425]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85297183-5f1f-4e3e-8b14-3d1ef0d10c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = pd.DataFrame(columns=['id', 'N_seqs', 'N_discarderd_singl', 'N_discarderd_len', 'N_discarded_quality', \\\n",
    "                             'N_discarded_align', 'N_discarded_overl', 'av_gene_len', \\\n",
    "                             'std_gene_len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a3e68e-993b-49e0-a0d7-9d6024b2a6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fastq in os.listdir('../fastq/hiv/'):\n",
    "    \n",
    "    if fastq.split('_')[-1] == '1.fastq':\n",
    "        id_ = fastq.split('_')[0]+'_'+fastq.split('_')[1]\n",
    "        print(id_)\n",
    "        \n",
    "        if id_+'_hiv.fasta' in os.listdir('../hiv_seqs/'):\n",
    "            print('already present, skip.')\n",
    "            continue\n",
    "        \n",
    "        name1, name2 = id_+'_hiv_1.fastq', id_+'_hiv_2.fastq'\n",
    "        reads1, reads2, quals1, quals2 = import_pair_reads('../fastq/hiv/', name1, name2)\n",
    "        seqs, l_fail, q_fail, sing_fail, a_fail = build_seq(reads1, reads2, quals1, quals2)\n",
    "        \n",
    "        info_d = {'id' : id_}\n",
    "        uniq_seqs, counts = np.unique(seqs, return_counts=True)\n",
    "        \n",
    "        info_d['N_seqs']= len(seqs)\n",
    "        info_d['N_unique_seqs']= len(uniq_seqs)\n",
    "        info_d['N_discarderd_len'] = l_fail\n",
    "        info_d['N_discarderd_singl'] = sing_fail\n",
    "        #info_d['N_discarded_overl'] = overl_fail\n",
    "        info_d['N_discarded_align'] = a_fail\n",
    "        info_d['N_discarded_quality'] = q_fail\n",
    "        lens = [len(s) for s in seqs]\n",
    "        info_d['av_gene_len'] = np.mean(lens)\n",
    "        info_d['std_gene_len'] = np.std(lens)\n",
    "        info = info.append(info_d, ignore_index=True)\n",
    "        \n",
    "        if len(uniq_seqs) > 0:\n",
    "            export_seqs(uniq_seqs, counts, id_+'_hiv', '../hiv_seqs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0385c57-1670-4993-803e-aa5c5d9b6781",
   "metadata": {},
   "outputs": [],
   "source": [
    "info.sort_index().to_csv('../hiv_seqs_info.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969ce425-ff1f-44f1-958e-0094516a2849",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
